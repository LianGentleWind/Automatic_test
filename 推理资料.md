运行命令：`python3 run.py -c ./configs/运行runtime.json`

运行runtime格式：
```
// example_config.json
{
     // 必选，部署形态，可选pd-fusion/split-request-optimal
    "pd-split-request-optimal": {
        // 必选，指定model config文件，可设置多个
        "model_list": [
            "./models/deepseek_v3_flash_mla_absorb.json",
            "./models/llama_3_8b.json",
            "./models/llama_3_70b.json",
            "./models/gpt_3_175b.json"
        ],
        // 必选，负载输入输出长度，可设置多个
        "sequence_length_list": [
            [
                4096,
                1024
            ]
        ],
        // 必选，总卡数，PD分离时为P卡+D卡
        "num_procs_list": [
            356
        ],
        // 可选，当PD分离的时候，可指定P/D各自的数目；缺省None，自动寻优最佳PD配比
        "pd_num_procs_list": [
            [32, 320]
        ],
         // 可选，指定P阶段的部署策略 [DP, PP, TP]，当前PP未实现默认1，MoE模型为Attn部分部署策略
         // 缺省None，自动寻优最佳部署策略
        "p_parallel_config": [
            [8, 1, 4]
        ],
        // 可选，仅MoE模型生效，指定P阶段的MoE部署策略 [EP, Moe_TP, Moe_DP]
        // 缺省None，自动寻优最佳部署策略
        "p_moe_parallel_config": [
            [32, 1, 1]
        ],
        // 可选，指定D阶段的部署策略 [DP, PP, TP]，当前PP未实现默认1，MoE模型为Attn部分部署策略
        // 缺省None，自动寻优最佳部署策略
        "d_parallel_config": null,
        // 可选，仅MoE模型生效，指定D阶段的MoE部署策略 [EP, Moe_TP, Moe_DP]
        // 缺省None，自动寻优最佳部署策略
        "d_moe_parallel_config": null,
        // 可选，P阶段batch_size设置[global_bs, num_bs, bs]，建议默认[1,1,1]节省寻优时间（prefill阶段计算Bound，并发对吞吐理论无影响）
        // 缺省None，自动寻优最高并发
        "p_micro_batch_size": [
            [1,1,1]
        ],
        // 可选，D阶段batch_size设置[global_bs, num_bs, bs]，例如[32, 1, 32]
        // 缺省None，自动寻优最高并发
        "d_micro_batch_size": null,
        // 可选，仅MoE模型decode生效，D阶段基于卡数寻优不同冗余专家个数时的部署策略，可选int类型指定冗余专家数目，可选list例如[1, 96]，在该范围内寻优最优专家部署策略
        // 缺省None，默认模型的冗余专家设置，例如DS-V3=32
        "num_redundant_experts_config": 32,
        // 可选，仅MoE模型decode生效，指定true时，考虑decode阶段每卡部署1个共享专家
        // 缺省false，不考虑每卡部署1个共享专家，默认模型共享专家数例如DS-V3=32
        "deploy_shared_expert_config": false,
       // 必选，依次为[weight_quant, activation_quant, cache_quant, communication_quant]，注意激活量化必须和下列的matrix flops算力保持一致，例如activation_quant=1时，matrix flops type必须为float8
        "wac_bytes_list": [
            [
                1,
                1,
                1,
                2
            ]
        ],
        // 必选，依次为[matrix_flops_type, attn_flops_type, vector_flops_type], 可选择key需在芯片配置中体现
        "flops_type_list": [
            ["float8", "float16", "float16"]
        ],
        // 必选，TTFT和TPOT约束，单位ms，无约束时可配置[null, null]
        "time_limit_list": [
            [
                null,
                50
            ]
        ],
        // 必选，芯片配置，PD分离时需分别配置P芯片和D芯片，PD融合仅需配置一个芯片
        "sys_list": [
            [
                "./systems/systems_without_compute_calibration/910C_with_1die.json",
                "./systems/systems_without_compute_calibration/910C_with_1die.json"
            ],
            [
                "./systems/systems_without_compute_calibration/H800_IB.json",
                "./systems/systems_without_compute_calibration/H800_IB.json"
            ]
        ],
        // 必选，结果输出目录
        "output": "./outputs/test/pd_split"
    },
    "pd-fusion": {
        "model_list": [
            "./models/deepseek_v3_flash_mla_absorb.json",
            "./models/llama_3_8b.json",
            "./models/llama_3_70b.json",
            "./models/gpt_3_175b.json"
        ],
        "sequence_length_list": [
            [
                4096,
                1024
            ]
        ],
        "num_procs_list": [
            32
        ],
        "parallel_config": [
            [8, 1, 4]
        ],
        "moe_parallel_config": null,
        "batch_config": [
            [32,1,32]
        ],
        "num_redundant_experts_config": [0, 96],
        "deploy_shared_expert_config": true,
        "decode_mtp_token_config": 0,
        "wac_bytes_list": [
            [
                1,
                1,
                1,
                1
            ]
        ],
        "flops_type_list": [
            ["float8", "float16", "float16"],
            ["float8", "float8", "float8"]
        ],
        "time_limit_list": [
            [
                null,
                50
            ]
        ],
        "sys_list": [
            "./systems/systems_without_compute_calibration/910C_with_1die.json"
        ],
        "output": "./outputs/test/pd_fusion"
    }
}
```
runtime中需要配置系统参数sys_list的json文件，和运行的大模型model的json，格式：
```
{
    "name": "SOW-S1",   					# 硬件名
    "type": "sow",						# 硬件类型
    "matrix": {							#Cube算力
        "float16": {						#FP16
            "tflops": 1000,					#单位为T
            "calibration_coefficient": 0.8,		#Cube为0.8，Vector为0.1
            "gflops_efficiency": [				#不同运算量下的效率，默认配1
                [
                    null,
                    null,
                    null,
                    1.0
                ]
            ]
        },
        "float8": {
            "tflops": 2000,
            "calibration_coefficient": 0.8,
            "gflops_efficiency": [
                [
                    null,
                    null,
                    null,
                    1.0
                ]
            ]
        },
        "float4": {
            "tflops": 6000,
            "calibration_coefficient": 0.8,
            "gflops_efficiency": [
                [
                    null,
                    null,
                    null,
                    1.0
                ]
            ]
        }
    },
    "vector": {
        "float16": {
            "tflops": 125,
            "calibration_coefficient": 0.1,
            "gflops_efficiency": [
                [
                    0,
                    1.0
                ]
            ]
        },
        "float8": {
            "tflops": 250,
            "calibration_coefficient": 0.1,
            "gflops_efficiency": [
                [
                    0,
                    1.0
                ]
            ]
        },
        "float4": {
            "tflops": 750,
            "calibration_coefficient": 0.1,
            "gflops_efficiency": [
                [
                    0,
                    1.0
                ]
            ]
        }
    },
    "mem1": {											#HBM层
        "GiB": 57.6,										#容量
        "GBps": 4571,										#带宽
        "calibration_coefficient": 0.8,							#默认0.8
        "page_attention_calibration_coefficient": 1,				#暂无效果？
        "page_attention_calibration_coefficient_prefill": 1,
        "kv_cache_calibration_coefficient": 1,
        "kv_cache_calibration_coefficient_prefill": 1,
        "MB_efficiency": [
            [
                0,
                1
            ]
        ]
    },
    "mem2": {											#第二层存储，暂无效果
        "GiB": 192,
        "GBps": 47.6,
        "MB_efficiency": [
            [
                0,
                1
            ]
        ]
    },
    "processing_mode": "roofline",							#roofline仿真方法
    "networks": [										#网络互联配置
        {												#第一层网络
            "bandwidth": 12000,								#带宽，单位GBps
            "efficiency": 0.8,									#校正效率
            "topology": "2dfm",								#默认选这个2dfm
            "DB_efficiency": [									#不同通信量的效率，默认值
                [
                    1,
                    1
                ]
            ],
            "size": 10,										#第一层组网节点数
            "latency": 3e-8,									#单跳延时，单位s
            "ops": {											#不同算子的运算效率
                "p2p": {										#p2p
                    "op_scalar":[								#整体缩放系数？
                        1.0,
                        null
                    ],
                    "bandwidth_eff": [							#分组数目和对应的运算效率。没有匹配值时，取下面list的最低值。
                        [
                            2,
                            0.8
                        ],
                        [
                            5,
                            0.8
                        ],
                        [
                            10,
                            0.8
                        ]
                    ]
                },
                "reduce_scatter": {
                    "op_scalar":[
                        1.0,
                        0
                    ],
                    "bandwidth_eff": [
                        [
                            2,
                            0.8
                        ],
                        [
                            5,
                            0.8
                        ],
                        [
                            10,
                            0.8
                        ]
                    ]
                },
                "all_gather": {
                    "op_scalar":[
                        1.0,
                        0
                    ],
                    "bandwidth_eff": [
                        [
                            2,
                            0.8
                        ],
                        [
                            5,
                            0.8
                        ],
                        [
                            10,
                            0.8
                        ]
                    ]
                },
                "all_reduce": {
                    "op_scalar": [
                        2.0,
                        -1
                    ],
                    "bandwidth_eff": [
                        [
                            2,
                            0.8
                        ],
                        [
                            5,
                            0.8
                        ],
                        [
                            10,
                            0.8
                        ]
                    ]
                },
                "all2all": {
                    "op_scalar":[
                        1.0,
                        0
                    ],
                    "bandwidth_eff": [
                        [
                            2,
                            0.8
                        ],
                        [
                            5,
                            0.8
                        ],
                        [
                            10,
                            0.8
                        ]
                    ]
                }
            },
            "processor_usage": 0						#通信对计算算力的占用率
        },       
        {										#第二层网络
            "bandwidth": 1000,
            "efficiency": 0.8,
            "topology": "2dfm",
            "DB_efficiency": [
                [
                    1,
                    1
                ]
            ],
            "size": 65536,
            "latency": 5e-6,
            "ops": {
                "p2p": {
                    "op_scalar":[
                        1.0,
                        null
                    ],
                    "bandwidth_eff": [
                        [
                            2,
                            0.5
                        ],
                        [
                            4,
                            0.5
                        ]
                    ]
                },
                "reduce_scatter": {
                    "op_scalar":[
                        1.0,
                        0
                    ],
                    "bandwidth_eff": [
                        [
                            2,
                            0.5312
                        ],
                        [
                            4,
                            0.3924
                        ]
                    ]
                },
                "all_gather": {
                    "op_scalar":[
                        1.0,
                        0
                    ],
                    "bandwidth_eff": [
                        [
                            2,
                            0.6875
                        ],
                        [
                            4,
                            0.5781
                        ]
                    ]
                },
                "all_reduce": {
                    "op_scalar": [
                        2.0,
                        -1
                    ],
                    "bandwidth_eff": [
                        [
                            2,
                            0.5312
                        ],
                        [
                            4,
                            0.3924
                        ]
                    ]
                },
                "all2all": {
                    "op_scalar":[
                        1.0,
                        0
                    ],
                    "bandwidth_eff": [
                        [
                            2,
                            0.6875
                        ],
                        [
                            4,
                            0.5781
                        ]
                    ]
                }
            },
            "processor_usage": 0.06
        }
    ]
}
```
大模型的模型配置：
```
非MoE模型，Qwen-32B-flash：
{
    "hidden": 5120,
    "feedforward": 25600,
    "seq_size": null,
    "cache_len": 0,
    "attn_heads": 64,
    "kv_heads": 8,
    "attn_type": "group-query",
    "attn_size": 128,
    "num_blocks": 64,
    "output_seq": null,
    "model": "qwen3-32B-flash",
    "use_flash_attn": true,
    "weight_byte": 1,
    "activation_byte": 1,
    "cache_byte": 1
}
```
```
MoE模型，DeepSeekV3：
{
    "hidden": 7168,
    "feedforward": 18432,
    "moe_intermediate_size":2048,
    "seq_size": 1024,
    "attn_heads": 128,
    "attn_size": 80,
    "num_blocks": 61,
    "num_experts": 256,
    "num_redundant_experts": 32,
    "num_shared_experts": 32,
    "n_shared_experts":1,
    "top_experts_activation": 8,
    "moe_capacity_factor": 1,
    "moe_block_interval": 0,
    "output_seq": 1024,
    "model": "deepseek-v3-mla-absorb",
    "kv_heads": 128,
    "attn_type": "mla-absorb",
    "use_flash_attn": true,
    "ffn_dim_multiplier": 1,
    "multiple_of": 256,
    "has_attn_gate": false,
    "q_lora_rank": 1536,
    "qk_nope_head_dim":128,
    "qk_rope_head_dim": 64,
    "kv_lora_rank":512,
    "v_head_dim":128,
    "weight_byte": 1,
    "activation_byte": 1,
    "cache_byte": 1
}
```
仿真程序结束后，输出csv文件的函数：
```
def write_output_wide_csv(out_put_file, logger, output):
    if not output:
        return

    os.makedirs(os.path.dirname(out_put_file), exist_ok=True)
    logger.info(f'Output Wide CSV: {out_put_file}')

    # 获取第一组数据用于确定字段顺序
    first_model, first_sys, first_exe, first_stats = output[0]

    # 定义特定的吞吐量字段
    tp_keys = ['prefill_throughput(token/s)', 'prefill_throughput_per_npu(token/s)', 'decoder_throughput(token/s)', 'decoder_throughput_per_npu(token/s)']
    # 过滤掉 stats 中重复的部分
    remaining_stats_keys = [k for k in first_stats.keys() if k not in tp_keys]

    # 定义数据列表和对应的源: (key列表, 数据源标识)
    structure = [
        (list(first_model.keys()), 'model'),
        (tp_keys, 'stats'),
        (list(first_sys.keys()), 'system'),
        (list(first_exe.keys()), 'execution'),
        (remaining_stats_keys, 'stats')
    ]

    opener = gzip.open if out_put_file.endswith('.gz') else open
    
    with opener(out_put_file, 'wb') as fd:
        # 写入表头：field_name, run_0, run_1, ...
        header = 'field_name'
        for i in range(len(output)):
            header += f',run_{i}'
        fd.write(bytes(header + '\n', 'utf-8'))

        # 按顺序写入行
        for keys, source_type in structure:
            for key in keys:
                # 第一列直接写入原始字段名
                row_str = f'{key}'
                
                # 遍历所有实验结果提取对应值
                for run in output:
                    model, sys, exe, stats = run
                    
                    # 根据数据源标识选择字典
                    if source_type == 'model':
                        val = model.get(key, '')
                    elif source_type == 'system':
                        val = sys.get(key, '')
                    elif source_type == 'execution':
                        val = exe.get(key, '')
                        # 处理可能包含逗号的特殊字段，避免 CSV 格式错乱
                        if key == 'expert_par_net':
                            val = str(val).replace(',', ' ')
                    elif source_type == 'stats':
                        val = stats.get(key, '')
                    
                    row_str += f',{val}'
                
                fd.write(bytes(row_str + '\n', 'utf-8'))
```
output的csv中会根据runtime中配置的任务数量，生成多行结果，例如model_list中写了4个模型，就会生成四行结果。
输出的csv文件：
```
field_name	run_0	run_1	run_2	run_3
model_name	deepseek-v3-mla-absorb	deepseek-v3-mla-absorb	qwen3-32B-flash	qwen3-32B-flash
seq_size	4096	4096	4096	4096
out_size	1024	1024	1024	1024
weight_byte	0.5	0.5	0.5	0.5
activation_byte	0.5	0.5	0.5	0.5
cache_byte	1	1	1	1
comm_byte	1	1	1	1
use_flash_attn	TRUE	TRUE	TRUE	TRUE
prefill_throughput(token/s)				
prefill_throughput_per_npu(token/s)				
decoder_throughput(token/s)	72352.91853	72352.91853	297004.6794	297004.6794
decoder_throughput_per_npu(token/s)	2009.803293	2009.803293	8250.129982	8250.129982
decoder_system_name	SOW-U1-POR	SOW-U1-POR_12	SOW-U1-POR	SOW-U1-POR_12
decoder_matix_flops	5587.935448	5587.935448	5587.935448	5587.935448
decoder_mem1_capacity(Gib)	72	72	72	72
decoder_mem1_bindwidth(GBps)	6683	6683	6683	6683
decoder_network0_bw(GBps)	12000	12000	12000	12000
decoder_network0_latency(s)	3.00E-08	3.00E-08	3.00E-08	3.00E-08
decoder_network1_bw(GBps)	1000	1000	1000	1000
decoder_network1_latency(s)	5.00E-06	5.00E-06	5.00E-06	5.00E-06
decoder_num_procs	36	36	36	36
decoder_num_npu	36	36	36	36
decoder_dp	12	12	9	9
decoder_tp	1	1	4	4
decoder_pp	3	3	1	1
decoder_cp	1	1	1	1
decoder_sp	1	1	1	1
decoder_moe_dp	9	9	0	0
decoder_moe_tp	1	1	1	1
decoder_ep	4	4	1	1
decoder_microbatchsize	70	70	437	437
decoder_attn_microbatchsize	210	210	0	0
decoder_card_mbs	70	70	109.25	109.25
decoder_flops_type	float4 float8 float4	float4 float8 float4	float4 float8 float4	float4 float8 float4
decoder_mtp_token	0	0	0	0
decoder_time_limit(ms)	50	50	50	50
decoder_TPS	20	20	20	20
decoder_moe_redundant_expert_num	32	32	0	0
decoder_deploy_shared_expert_for_each_npu	FALSE	FALSE	FALSE	FALSE
decoder_request_per_second	70.657147	70.657147	290.0436322	290.0436322
decoder_mbs_time(s)	35.66518189	35.66518189	13.56002878	13.56002878
decoder_tp_comm_time(s)	0	0	0	0
decoder_ep_comm_time(s)	0	0	0	0
decoder_cp_comm_time(s)	0	0	0	0
decoder_sp_comm_time(s)	0	0	0	0
decoder_time_per_token(s)	0.034829279	0.034829279	0.013242216	0.013242216
decoder_attn_time_per_token(s)	0.005101872	0.005101872	0	0
decoder_mlp_time_per_token(s)	0.006506397	0.006506397	0	0
decoder_instance_compute_time_used(s)	0.001795436	0.001795436	0.001521488	0.001521488
decoder_instance_mem_time_used(s)	0.009812834	0.009812834	0.011720727	0.011720727
decoder_instance_comm_time_exposed(s)	0	0	0	0
decoder_instance_cube_process_time(s)	0.010598325	0.010598325	0.012893985	0.012893985
decoder_instance_vector_process_time(s)	0.001009944	0.001009944	0.000348231	0.000348231
decoder_instance_compute_time(s)	0.004249544	0.004249544	0.001781358	0.001781358
decoder_instance_mem_time(s)	0.009970162	0.009970162	0.012557987	0.012557987
decoder_instance_attn_process_time(s)	0.005101872	0.005101872	0.011983156	0.011983156
decoder_instance_attn_mem_accessed	19125610560	19125610560	67584794624	67584794624
decoder_instance_attn_mem_time(s)	0.003331609	0.003331609	0.011773015	0.011773015
decoder_instance_attn_flops	7.32793E+12	7.32793E+12	2.3877E+12	2.3877E+12
decoder_instance_attn_compute_time(s)	0.004004465	0.004004465	0.000638399	0.000638399
decoder_instance_attn_bmm_compute_time(s)	0.001626055	0.001626055	0	0
decoder_instance_attn_bmm_mem_time(s)	0.002067738	0.002067738	0.011506772	0.011506772
decoder_instance_attn_ffn_compute_time(s)	0	0	0.000268493	0.000268493
decoder_instance_attn_ffn_mem_time(s)	0.000430552	0.000430552	0	0
decoder_instance_mlp_process_time(s)	0.006506397	0.006506397	0.00125906	0.00125906
decoder_instance_mlp_weight_space(Gib)	34.47120953	34.47120953	0	0
decoder_instance_attn_weight_space(Gib)	1.829701424	1.829701424	0	0
decoder_instance_mlp_act_working_space(Gib)	0.008411407	0.008411407	0	0
decoder_instance_attn_act_working_space(Gib)	0.05769074	0.05769074	0	0
decoder_instance_mlp_mem_accessed	38109633282	38109633282	4506255360	4506255360
decoder_instance_mlp_mem_time(s)	0.006638553	0.006638553	0.000784973	0.000784973
decoder_instance_mlp_flops	1.18185E+12	1.18185E+12	5.5007E+12	5.5007E+12
decoder_instance_mlp_compute_time(s)	0.000245079	0.000245079	0.001142959	0.001142959
decoder_instance_mlp_ffn_compute_time(s)	0	0	0.00111872	0.00111872
decoder_instance_mlp_ffn_mem_time(s)	0.00647398	0.00647398	0	0
decoder_mem_space(Gib)	36.35860169	36.35860169	3.635730028	3.635730028
decoder_tier1_mem(Gib)	71.54231751	71.54231751	71.91698003	71.91698003
decoder_tp_comm_mem_size(Gib)	0	0	546.25	546.25
decoder_ep_comm_mem_size(Gib)	180.8789063	180.8789063	0	0
decoder_cp_comm_mem_size(Gib)	0	0	0	0
decoder_sp_comm_mem_size(Gib)	0	0	0	0
kv_cache_total_mem(Gib)	35.18371582	35.18371582	68.28125	68.28125


```
或者
```
|   |   |   |   |   |   |
|---|---|---|---|---|---|
|category|field_name|run_0|run_1|run_2|run_3|
|model_basic_config|model_name|deepseek-v3-mla-absorb|deepseek-v3-mla-absorb|qwen3-32B-flash|qwen3-32B-flash|
|model_basic_config|seq_size|4096|4096|4096|4096|
|model_basic_config|out_size|1024|1024|1024|1024|
|model_basic_config|weight_byte|0.5|0.5|0.5|0.5|
|model_basic_config|activation_byte|0.5|0.5|0.5|0.5|
|model_basic_config|cache_byte|1|1|1|1|
|model_basic_config|comm_byte|1|1|1|1|
|model_basic_config|use_flash_attn|TRUE|TRUE|TRUE|TRUE|
|performance_throughput|prefill_throughput(token/s)|   |   |||
|performance_throughput|prefill_throughput_per_npu(token/s)|   |   |   ||
|performance_throughput|decoder_throughput(token/s)|72352.92|72352.92|297004.7|297004.7|
|performance_throughput|decoder_throughput_per_npu(token/s)|2009.803|2009.803|8250.13|8250.13|
|system_resource_config|decoder_system_name|SOW-U1-POR|SOW-U1-POR_12|SOW-U1-POR|SOW-U1-POR_12|
|system_resource_config|decoder_matix_flops|5587.935|5587.935|5587.935|5587.935|
|system_resource_config|decoder_mem1_capacity(Gib)|72|72|72|72|
|system_resource_config|decoder_mem1_bindwidth(GBps)|6683|6683|6683|6683|
|system_resource_config|decoder_network0_bw(GBps)|12000|12000|12000|12000|
|system_resource_config|decoder_network0_latency(s)|3.00E-08|3.00E-08|3.00E-08|3.00E-08|
|system_resource_config|decoder_network1_bw(GBps)|1000|1000|1000|1000|
|system_resource_config|decoder_network1_latency(s)|5.00E-06|5.00E-06|5.00E-06|5.00E-06|
|parallel_strategy_config|decoder_num_procs|36|36|36|36|
|parallel_strategy_config|decoder_num_npu|36|36|36|36|
|parallel_strategy_config|decoder_dp|12|12|9|9|
|parallel_strategy_config|decoder_tp|1|1|4|4|
|parallel_strategy_config|decoder_pp|3|3|1|1|
|parallel_strategy_config|decoder_cp|1|1|1|1|
|parallel_strategy_config|decoder_sp|1|1|1|1|
|parallel_strategy_config|decoder_moe_dp|9|9|0|0|
|parallel_strategy_config|decoder_moe_tp|1|1|1|1|
|parallel_strategy_config|decoder_ep|4|4|1|1|
|parallel_strategy_config|decoder_microbatchsize|70|70|437|437|
|parallel_strategy_config|decoder_attn_microbatchsize|210|210|0|0|
|parallel_strategy_config|decoder_card_mbs|70|70|109.25|109.25|
|parallel_strategy_config|decoder_flops_type|float4 float8 float4|float4 float8 float4|float4 float8 float4|float4 float8 float4|
|parallel_strategy_config|decoder_mtp_token|0|0|0|0|
|parallel_strategy_config|decoder_time_limit(ms)|50|50|50|50|
|parallel_strategy_config|decoder_TPS|20|20|20|20|
|parallel_strategy_config|decoder_moe_redundant_expert_num|32|32|0|0|
|parallel_strategy_config|decoder_deploy_shared_expert_for_each_npu|FALSE|FALSE|FALSE|FALSE|
|other_stats_metrics|decoder_request_per_second|70.65715|70.65715|290.0436|290.0436|
|other_stats_metrics|decoder_mbs_time(s)|35.66518|35.66518|13.56003|13.56003|
|other_stats_metrics|decoder_tp_comm_time(s)|0|0|0|0|
|other_stats_metrics|decoder_ep_comm_time(s)|0|0|0|0|
|other_stats_metrics|decoder_cp_comm_time(s)|0|0|0|0|
|other_stats_metrics|decoder_sp_comm_time(s)|0|0|0|0|
|other_stats_metrics|decoder_time_per_token(s)|0.034829|0.034829|0.013242|0.013242|
|other_stats_metrics|decoder_attn_time_per_token(s)|0.005102|0.005102|0|0|
|other_stats_metrics|decoder_mlp_time_per_token(s)|0.006506|0.006506|0|0|
|other_stats_metrics|decoder_instance_compute_time_used(s)|0.001795|0.001795|0.001521|0.001521|
|other_stats_metrics|decoder_instance_mem_time_used(s)|0.009813|0.009813|0.011721|0.011721|
|other_stats_metrics|decoder_instance_comm_time_exposed(s)|0|0|0|0|
|other_stats_metrics|decoder_instance_cube_process_time(s)|0.010598|0.010598|0.012894|0.012894|
|other_stats_metrics|decoder_instance_vector_process_time(s)|0.00101|0.00101|0.000348|0.000348|
|other_stats_metrics|decoder_instance_compute_time(s)|0.00425|0.00425|0.001781|0.001781|
|other_stats_metrics|decoder_instance_mem_time(s)|0.00997|0.00997|0.012558|0.012558|
|other_stats_metrics|decoder_instance_attn_process_time(s)|0.005102|0.005102|0.011983|0.011983|
|other_stats_metrics|decoder_instance_attn_mem_accessed|1.91E+10|1.91E+10|6.76E+10|6.76E+10|
|other_stats_metrics|decoder_instance_attn_mem_time(s)|0.003332|0.003332|0.011773|0.011773|
|other_stats_metrics|decoder_instance_attn_flops|7.33E+12|7.33E+12|2.39E+12|2.39E+12|
|other_stats_metrics|decoder_instance_attn_compute_time(s)|0.004004|0.004004|0.000638|0.000638|
|other_stats_metrics|decoder_instance_attn_bmm_compute_time(s)|0.001626|0.001626|0|0|
|other_stats_metrics|decoder_instance_attn_bmm_mem_time(s)|0.002068|0.002068|0.011507|0.011507|
|other_stats_metrics|decoder_instance_attn_ffn_compute_time(s)|0|0|0.000268|0.000268|
|other_stats_metrics|decoder_instance_attn_ffn_mem_time(s)|0.000431|0.000431|0|0|
|other_stats_metrics|decoder_instance_mlp_process_time(s)|0.006506|0.006506|0.001259|0.001259|
|other_stats_metrics|decoder_instance_mlp_weight_space(Gib)|34.47121|34.47121|0|0|
|other_stats_metrics|decoder_instance_attn_weight_space(Gib)|1.829701|1.829701|0|0|
|other_stats_metrics|decoder_instance_mlp_act_working_space(Gib)|0.008411|0.008411|0|0|
|other_stats_metrics|decoder_instance_attn_act_working_space(Gib)|0.057691|0.057691|0|0|
|other_stats_metrics|decoder_instance_mlp_mem_accessed|3.81E+10|3.81E+10|4.51E+09|4.51E+09|
|other_stats_metrics|decoder_instance_mlp_mem_time(s)|0.006639|0.006639|0.000785|0.000785|
|other_stats_metrics|decoder_instance_mlp_flops|1.18E+12|1.18E+12|5.5E+12|5.5E+12|
|other_stats_metrics|decoder_instance_mlp_compute_time(s)|0.000245|0.000245|0.001143|0.001143|
|other_stats_metrics|decoder_instance_mlp_ffn_compute_time(s)|0|0|0.001119|0.001119|
|other_stats_metrics|decoder_instance_mlp_ffn_mem_time(s)|0.006474|0.006474|0|0|
|other_stats_metrics|decoder_mem_space(Gib)|36.3586|36.3586|3.63573|3.63573|
|other_stats_metrics|decoder_tier1_mem(Gib)|71.54232|71.54232|71.91698|71.91698|
|other_stats_metrics|decoder_tp_comm_mem_size(Gib)|0|0|546.25|546.25|
|other_stats_metrics|decoder_ep_comm_mem_size(Gib)|180.8789|180.8789|0|0|
|other_stats_metrics|decoder_cp_comm_mem_size(Gib)|0|0|0|0|
|other_stats_metrics|decoder_sp_comm_mem_size(Gib)|0|0|0|0|
|other_stats_metrics|kv_cache_total_mem(Gib)|35.18372|35.18372|68.28125|68.28125|
```
